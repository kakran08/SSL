{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP++/LENabbXqypUinQQ7JB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jQaLU1eaPRA_"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, Subset\n","import numpy as np\n","from torchvision import datasets, transforms"]},{"cell_type":"code","source":["# Setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.manual_seed(0)\n","\n","# ---------------------------------------------\n","# Step 1: Prepare Data (Reuses existing loaders)\n","# ---------------------------------------------\n","transform = transforms.Compose([\n","    transforms.ToTensor()\n","])\n","\n","train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","# Split into labeled and unlabeled sets\n","def split_labeled_unlabeled(dataset, num_labels=100):\n","    targets = np.array(dataset.targets)\n","    labeled_idx = []\n","    for i in range(10):\n","        idx = np.where(targets == i)[0][:num_labels // 10]\n","        labeled_idx.extend(idx)\n","    unlabeled_idx = list(set(range(len(dataset))) - set(labeled_idx))\n","    return Subset(dataset, labeled_idx), Subset(dataset, unlabeled_idx)\n","\n","labeled_dataset, unlabeled_dataset = split_labeled_unlabeled(train_dataset)\n","labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n","unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=128, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"],"metadata":{"id":"XBxxtRFNPi4u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------\n","# Step 2: VAE Model with Classifier\n","# ---------------------------------------------\n","def one_hot(y, num_classes=10):\n","    return F.one_hot(y, num_classes=num_classes).float()\n","\n","class Encoder(nn.Module):\n","    def __init__(self, latent_dim=20, n_classes=10):\n","        super().__init__()\n","        self.fc1 = nn.Linear(784 + n_classes, 400)\n","        self.fc_mu = nn.Linear(400, latent_dim)\n","        self.fc_logvar = nn.Linear(400, latent_dim)\n","\n","    def forward(self, x, y):\n","        xy = torch.cat([x, y], dim=1)\n","        h = F.relu(self.fc1(xy))\n","        return self.fc_mu(h), self.fc_logvar(h)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, latent_dim=20, n_classes=10):\n","        super().__init__()\n","        self.fc1 = nn.Linear(latent_dim + n_classes, 400)\n","        self.fc2 = nn.Linear(400, 784)\n","\n","    def forward(self, z, y):\n","        zy = torch.cat([z, y], dim=1)\n","        h = F.relu(self.fc1(zy))\n","        return torch.sigmoid(self.fc2(h))  # Ensure output in [0, 1]\n","\n","class Classifier(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc = nn.Linear(784, 10)\n","\n","    def forward(self, x):\n","        return F.log_softmax(self.fc(x), dim=1)\n","\n","def kl_divergence(mu, logvar):\n","    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1)\n","\n","def reconstruction_loss(x_recon, x_true):\n","    x_recon = torch.clamp(x_recon, 1e-6, 1 - 1e-6)  # avoid log(0)\n","    x_true = torch.clamp(x_true, 0, 1)\n","    assert x_recon.shape == x_true.shape, f\"Shape mismatch: {x_recon.shape} vs {x_true.shape}\"\n","    return F.binary_cross_entropy(x_recon, x_true, reduction='none').sum(dim=1)"],"metadata":{"id":"O1aTpTURPo-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------\n","# Step 3: Full VAE-SSL Model\n","# ---------------------------------------------\n","class VAESSL(nn.Module):\n","    def __init__(self, latent_dim=20, n_classes=10):\n","        super().__init__()\n","        self.encoder = Encoder(latent_dim, n_classes)\n","        self.decoder = Decoder(latent_dim, n_classes)\n","        self.classifier = Classifier()\n","        self.n_classes = n_classes\n","        self.latent_dim = latent_dim\n","\n","    def forward_labeled(self, x, y):\n","        mu, logvar = self.encoder(x, y)\n","        std = torch.exp(0.5 * logvar)\n","        z = mu + std * torch.randn_like(std)\n","        x_recon = self.decoder(z, y)\n","        return x_recon, mu, logvar\n","\n","    def forward_unlabeled(self, x):\n","        log_probs = self.classifier(x)\n","        probs = log_probs.exp()\n","        total_loss = 0\n","        for i in range(self.n_classes):\n","            y_i = torch.eye(self.n_classes)[i].repeat(x.size(0), 1).to(device)\n","            mu, logvar = self.encoder(x, y_i)\n","            std = torch.exp(0.5 * logvar)\n","            z = mu + std * torch.randn_like(std)\n","            x_recon = self.decoder(z, y_i)\n","\n","            recon = reconstruction_loss(x_recon, x)\n","            kl = kl_divergence(mu, logvar)\n","            elbo = recon + kl - log_probs[:, i]\n","            total_loss += probs[:, i] * elbo\n","        return total_loss.mean()"],"metadata":{"id":"IZsJWnUEPwuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------\n","# Step 4: Training & Evaluation\n","# ---------------------------------------------\n","model = VAESSL().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","\n","def train_epoch(model, labeled_loader, unlabeled_loader, alpha=0.1, beta=1.0):\n","    model.train()\n","    total_labeled_loss = 0\n","    total_unlabeled_loss = 0\n","\n","    for (x_l, y_l), (x_u, _) in zip(labeled_loader, unlabeled_loader):\n","        x_l = x_l.view(-1, 784).to(device)\n","        x_u = x_u.view(-1, 784).to(device)\n","        y_l = y_l.to(device)\n","        y_l_1h = one_hot(y_l).to(device)\n","\n","        # Labeled VAE loss\n","        x_recon, mu, logvar = model.forward_labeled(x_l, y_l_1h)\n","        recon_loss = reconstruction_loss(x_recon, x_l)\n","        kl_loss = kl_divergence(mu, logvar)\n","        labeled_vae_loss = (recon_loss + kl_loss).mean()\n","\n","        # âž• Supervised classifier loss\n","        class_pred = model.classifier(x_l)\n","        class_loss = F.nll_loss(class_pred, y_l)\n","\n","        # Unlabeled VAE loss\n","        unlabeled_loss = model.forward_unlabeled(x_u)\n","\n","        # Total loss\n","        loss = labeled_vae_loss + alpha * unlabeled_loss + beta * class_loss\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        total_labeled_loss += (labeled_vae_loss + beta * class_loss).item()\n","        total_unlabeled_loss += unlabeled_loss.item()\n","\n","    return total_labeled_loss, total_unlabeled_loss\n","\n","\n","def evaluate_classifier(model, loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x = x.view(-1, 784).to(device)\n","            y = y.to(device)\n","            pred = model.classifier(x).argmax(1)\n","            correct += (pred == y).sum().item()\n","    return correct / len(loader.dataset)"],"metadata":{"id":"vsM00tWNP1xk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---------------------------------------------\n","# Step 5: Training Loop\n","# ---------------------------------------------\n","for epoch in range(1, 21):\n","    l_loss, u_loss = train_epoch(model, labeled_loader, unlabeled_loader, alpha=0.1)\n","    acc = evaluate_classifier(model, test_loader)\n","    print(f\"Epoch {epoch:02d} | Test Accuracy: {acc:.4f} | Labeled Loss: {l_loss:.2f} | Unlabeled Loss: {u_loss:.2f}\")"],"metadata":{"id":"ee6VpFFBP59k"},"execution_count":null,"outputs":[]}]}