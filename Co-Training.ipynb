{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNaR8GirCprtQ5O5G/D1RDI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K0Yrj5b1OU9l"},"outputs":[],"source":["# SSL : Co-Training\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader,Subset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["# -------------------------\n","# Step 1: Data Preparation\n","# -------------------------\n","\n","# Transform: Normalize MNIST images\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","# Load full MNIST dataset\n","train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","# Create labeled subset (e.g., 100 examples evenly distributed across classes)\n","num_labels = 100\n","labels = np.array(train_dataset.targets)\n","labeled_idx = []\n","\n","for i in range(10):\n","    idx = np.where(labels == i)[0][:num_labels // 10]\n","    labeled_idx.extend(idx)\n","\n","unlabeled_idx = list(set(range(len(train_dataset))) - set(labeled_idx))\n","\n","labeled_dataset = Subset(train_dataset, labeled_idx)\n","unlabeled_dataset = Subset(train_dataset, unlabeled_idx)\n","\n","labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n","unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=128, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"],"metadata":{"id":"f8wPvHBhOt5c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SplitMNIST(Dataset):\n","    def __init__(self, dataset, side='left'):\n","        self.dataset = dataset\n","        self.side = side\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        x, y = self.dataset[idx]\n","        if self.side == 'left':\n","            return x[:, :, :14], y\n","        else:\n","            return x[:, :, 14:], y\n","\n","# Step 3: Define Half-CNN Model\n","class HalfCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(16 * 7 * 3, 64)  # Actually matches input from 28x14 images\n","        self.fc2 = nn.Linear(64, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))     # → [B, 16, 14, 7]\n","        x = self.pool(F.relu(self.conv2(x)))     # → [B, 16, 7, 3]\n","        x = x.view(x.size(0), -1)                # Flatten safely\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","# Step 4: Training and Evaluation Functions\n","def train(model, loader, optimizer):\n","    model.train()\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        output = model(x)\n","        loss = F.cross_entropy(output, y)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            pred = model(x).argmax(1)\n","            correct += (pred == y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","def generate_pseudo_labels(model, loader, threshold=0.95):\n","    model.eval()\n","    pseudo_x, pseudo_y = [], []\n","    with torch.no_grad():\n","        for x, _ in loader:\n","            x = x.to(device)\n","            logits = model(x)\n","            probs = F.softmax(logits, dim=1)\n","            conf, pred = torch.max(probs, 1)\n","            mask = conf > threshold\n","            if mask.any():\n","                pseudo_x.append(x[mask].cpu())\n","                pseudo_y.append(pred[mask].cpu())\n","    if pseudo_x:\n","        return torch.utils.data.TensorDataset(torch.cat(pseudo_x), torch.cat(pseudo_y))\n","    return None\n","\n","# Step 5: Initialize Models and Loaders\n","model1 = HalfCNN().to(device)\n","model2 = HalfCNN().to(device)\n","opt1 = optim.Adam(model1.parameters(), lr=1e-3)\n","opt2 = optim.Adam(model2.parameters(), lr=1e-3)\n","\n","view1_loader = DataLoader(SplitMNIST(labeled_dataset, 'left'), batch_size=64, shuffle=True)\n","view2_loader = DataLoader(SplitMNIST(labeled_dataset, 'right'), batch_size=64, shuffle=True)\n","unlabeled1 = DataLoader(SplitMNIST(unlabeled_dataset, 'left'), batch_size=256)\n","unlabeled2 = DataLoader(SplitMNIST(unlabeled_dataset, 'right'), batch_size=256)\n","\n","# Step 6: Co-Training Loop\n","for epoch in range(1, 11):\n","    print(f\"\\nEpoch {epoch}\")\n","\n","    # Train both models on current labeled data\n","    train(model1, view1_loader, opt1)\n","    train(model2, view2_loader, opt2)\n","\n","    # Generate pseudo-labels\n","    p1 = generate_pseudo_labels(model1, unlabeled1)\n","    p2 = generate_pseudo_labels(model2, unlabeled2)\n","\n","    if p1 and p2:\n","        print(f\"  Adding pseudo-labels: View1 ← {len(p2)} from model2, View2 ← {len(p1)} from model1\")\n","        pseudo_view1 = SplitMNIST(p1, side='right')   # model1 gets help from model2\n","        pseudo_view2 = SplitMNIST(p2, side='left')    # model2 gets help from model1\n","\n","        view1_loader = DataLoader(ConcatDataset([SplitMNIST(labeled_set, 'left'), pseudo_view2]), batch_size=64, shuffle=True)\n","        view2_loader = DataLoader(ConcatDataset([SplitMNIST(labeled_set, 'right'), pseudo_view1]), batch_size=64, shuffle=True)\n","\n","    acc1 = evaluate(model1, unlabeled1)\n","    acc2 = evaluate(model2, unlabeled2)\n","    print(f\"  View1 Accuracy: {acc1:.4f}, View2 Accuracy: {acc2:.4f}\")"],"metadata":{"id":"jr5Bt7ouO2MU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3utyyrTNPCak"},"execution_count":null,"outputs":[]}]}