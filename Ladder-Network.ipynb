{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfE//5AL3ZQzgPVAimbyjv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0ou1HLlRL2K9"},"outputs":[],"source":["# SSL : Ladder Network\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader,Subset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["# -------------------------\n","# Step 1: Data Preparation\n","# -------------------------\n","\n","# Transform: Normalize MNIST images\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","# Load full MNIST dataset\n","train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","# Create labeled subset (e.g., 100 examples evenly distributed across classes)\n","num_labels = 100\n","labels = np.array(train_dataset.targets)\n","labeled_idx = []\n","\n","for i in range(10):\n","    idx = np.where(labels == i)[0][:num_labels // 10]\n","    labeled_idx.extend(idx)\n","\n","unlabeled_idx = list(set(range(len(train_dataset))) - set(labeled_idx))\n","\n","labeled_dataset = Subset(train_dataset, labeled_idx)\n","unlabeled_dataset = Subset(train_dataset, unlabeled_idx)\n","\n","labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n","unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=128, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"],"metadata":{"id":"YvpqHspxM6rE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# add noise\n","\n","class GaussianNoise(nn.Module):\n","    def __init__(self, stddev):\n","        super().__init__()\n","        self.stddev = stddev\n","    def forward(self, x):\n","        if self.training:\n","            noise = torch.randn_like(x) * self.stddev\n","            return x + noise\n","        else:\n","            return x\n","\n","class Encoder(nn.Module):\n","    def __init__(self, noise_std):\n","        super().__init__()\n","        self.noise = GaussianNoise(noise_std)\n","        self.fc1 = nn.Linear(784, 1000)\n","        self.fc2 = nn.Linear(1000, 500)\n","        self.fc3 = nn.Linear(500, 250)\n","        self.fc4 = nn.Linear(250, 250)\n","        self.fc5 = nn.Linear(250, 10)\n","\n","    def forward(self, x):\n","        z = []\n","        x = x.view(-1, 784)\n","        x = self.noise(x)\n","        z1 = self.fc1(x)\n","        z.append(z1)\n","        z2 = self.fc2(F.relu(z1))\n","        z.append(z2)\n","        z3 = self.fc3(F.relu(z2))\n","        z.append(z3)\n","        z4 = self.fc4(F.relu(z3))\n","        z.append(z4)\n","        z5 = self.fc5(F.relu(z4))\n","        z.append(z5)\n","        return z\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(10, 250)    # reconstruct z4 (250)\n","        self.fc2 = nn.Linear(250, 250)   # reconstruct z3 (250)\n","        self.fc3 = nn.Linear(250, 500)   # reconstruct z2 (500)\n","        self.fc4 = nn.Linear(500, 1000)  # reconstruct z1 (1000)\n","\n","    def forward(self, z_corr):\n","        d1 = self.fc1(z_corr[-1])              # input: z5 (10)\n","        d2 = self.fc2(F.relu(d1))              # matches z3\n","        d3 = self.fc3(F.relu(d2))              # matches z2\n","        d4 = self.fc4(F.relu(d3))              # matches z1\n","        return [d4, d3, d2, d1]  # decoder outputs for z1 to z4"],"metadata":{"id":"rcVM2B5SM-m0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------\n","# Step 3: Training Functions\n","# -------------------------\n","\n","def supervised_loss(output, target):\n","    return F.cross_entropy(output, target)\n","\n","def reconstruction_loss(z_clean, z_recon):\n","    loss = 0\n","    # Match z1 to z4 with d4 to d1\n","    for zc, zr in zip(z_clean[:4], z_recon):  # z_clean[:4] = z1 to z4\n","        loss += F.mse_loss(zr, zc.detach())\n","    return loss\n","\n","def train_epoch(encoder, decoder, optimizer, labeled_loader, unlabeled_loader, alpha):\n","    encoder.train()\n","    decoder.train()\n","\n","    for (x_l, y_l), (x_u, _) in zip(labeled_loader, unlabeled_loader):\n","        x_l, y_l = x_l.to(device), y_l.to(device)\n","        x_u = x_u.to(device)\n","\n","        z_corr_l = encoder(x_l)\n","        z_clean_l = encoder(x_l)\n","        z_corr_u = encoder(x_u)\n","        z_clean_u = encoder(x_u)\n","\n","        output = z_corr_l[-1]\n","        loss_sup = supervised_loss(output, y_l)\n","\n","        recon_l = decoder(z_corr_l)\n","        recon_u = decoder(z_corr_u)\n","\n","        loss_unsup = reconstruction_loss(z_clean_l, recon_l) + reconstruction_loss(z_clean_u, recon_u)\n","\n","        loss = loss_sup + alpha * loss_unsup\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate(encoder, loader):\n","    encoder.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            output = encoder(x)[-1]\n","            pred = output.argmax(dim=1)\n","            correct += (pred == y).sum().item()\n","    return correct / len(loader.dataset)"],"metadata":{"id":"DZTwl15sNCHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# -------------------------\n","# Step 4: Training Loop\n","# -------------------------\n","\n","encoder = Encoder(noise_std=0.3).to(device)\n","decoder = Decoder().to(device)\n","optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=1e-3)\n","\n","epochs = 30\n","alpha = 0.5\n","\n","for epoch in range(1, epochs + 1):\n","    train_epoch(encoder, decoder, optimizer, labeled_loader, unlabeled_loader, alpha)\n","    test_acc = evaluate(encoder, test_loader)\n","    labeled_acc = evaluate(encoder, labeled_loader)\n","    unlabeled_acc = evaluate(encoder, DataLoader(unlabeled_dataset, batch_size=256))\n","    print(f\"Epoch {epoch:02d} | Test Acc: {test_acc:.4f} | Labeled Acc: {labeled_acc:.4f} | Unlabeled Pseudo Acc: {unlabeled_acc:.4f}\")"],"metadata":{"id":"m_7KO6AvNJk8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2uJRoRsNNKjc"},"execution_count":null,"outputs":[]}]}