{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCY1Zy5zq7Ox7oV85LaGCp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"FVOLJCP3OVjc","executionInfo":{"status":"ok","timestamp":1747373326789,"user_tz":-330,"elapsed":24662,"user":{"displayName":"Nikhil Kakran","userId":"16198073203878808755"}}},"outputs":[],"source":["# SSL : Self Training\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader,Subset,ConcatDataset\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","source":["# -------------------------\n","# Step 1: Data Preparation\n","# -------------------------\n","\n","# Transform: Normalize MNIST images\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","# Load full MNIST dataset\n","train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n","\n","# Create labeled subset (e.g., 100 examples evenly distributed across classes)\n","num_labels = 100\n","labels = np.array(train_dataset.targets)\n","labeled_idx = []\n","\n","for i in range(10):\n","    idx = np.where(labels == i)[0][:num_labels // 10]\n","    labeled_idx.extend(idx)\n","\n","unlabeled_idx = list(set(range(len(train_dataset))) - set(labeled_idx))\n","\n","labeled_dataset = Subset(train_dataset, labeled_idx)\n","unlabeled_dataset = Subset(train_dataset, unlabeled_idx)\n","\n","labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n","unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=128, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"],"metadata":{"id":"s0EedyudOp6M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Subset, ConcatDataset, Dataset\n","\n","# Step 2: CNN for self-training\n","class BaseCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n","        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 32 * 7 * 7)\n","        x = F.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","# Step 3: Supervised training\n","def train(model, loader, optimizer):\n","    model.train()\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        loss = F.cross_entropy(model(x), y)\n","        loss.backward()\n","        optimizer.step()\n","\n","# Step 4: Generate pseudo-labels for unlabeled data\n","def generate_pseudo_labels(model, loader, threshold=0.95):\n","    model.eval()\n","    pseudo_x, pseudo_y = [], []\n","    with torch.no_grad():\n","        for x, _ in loader:\n","            x = x.to(device)\n","            logits = model(x)\n","            probs = F.softmax(logits, dim=1)\n","            conf, pred = torch.max(probs, 1)\n","            mask = conf > threshold\n","            if mask.any():\n","                pseudo_x.append(x[mask])\n","                pseudo_y.append(pred[mask])\n","    if pseudo_x:\n","        return torch.utils.data.TensorDataset(torch.cat(pseudo_x), torch.cat(pseudo_y))\n","    return None\n","\n","def evaluate(model, loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for x, y in loader:\n","            x, y = x.to(device), y.to(device)\n","            pred = model(x).argmax(1)\n","            correct += (pred == y).sum().item()\n","    return correct / len(loader.dataset)\n","\n","# Step 5: Self-Training Loop\n","model = BaseCNN().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","for epoch in range(1, 11):\n","    train(model, labeled_loader, optimizer)\n","    pseudo_dataset = generate_pseudo_labels(model, unlabeled_loader, threshold=0.95)\n","    if pseudo_dataset:\n","        print(f\"Epoch {epoch}: Adding {len(pseudo_dataset)} pseudo-labeled samples.\")\n","        labeled_set = ConcatDataset([labeled_dataset, pseudo_dataset])\n","        labeled_loader = DataLoader(labeled_dataset, batch_size=64, shuffle=True)\n","    acc = evaluate(model, test_loader)\n","    print(f\"[Self-Training] Epoch {epoch} - Test Accuracy: {acc:.4f}\")"],"metadata":{"id":"iFJEjax2OqG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JWpXV8lEOqKF"},"execution_count":null,"outputs":[]}]}